{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b3bf67-9049-48c7-b854-f306f448572d",
   "metadata": {},
   "source": [
    "# VA Incarceration Status Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d89b567-160a-4bc5-bed7-6f12ae4dd745",
   "metadata": {},
   "source": [
    "This notebook describes how to run the HAIL Lab's Incarceration Status Longformer model and output results to a CSV file. It's broken down into the following sections: \n",
    "\n",
    "- What you need to start\n",
    "- Installing HAIL's Incarceration Status Model\n",
    "- Running the Incarceration Status Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf5977-fa72-4e72-a1c7-0fa4c71a9c1e",
   "metadata": {},
   "source": [
    "## What you need to start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69171e-3ba2-40c4-b296-2ab6425846c4",
   "metadata": {},
   "source": [
    "**1. You will need the following packages:**\n",
    "\n",
    "- pandas==1.5.0\n",
    "- numpy==1.23.4\n",
    "- tqdm==4.64.1\n",
    "- pytorch==1.10.1\n",
    "    - version including CUDA: py3.9_cuda10.2_cudnn7.6.5_0\n",
    "- transformers==4.20.1\n",
    "    - huggingface library\n",
    "- datasets==2.12.0\n",
    "- evaluate==0.4.0\n",
    "- huggingface-hub==0.8.1\n",
    "    - where you'll get the trained Longformer model\n",
    "\n",
    "\n",
    "**2. You will also need your data in a CSV file format.**  \n",
    "**3. You will need the HAIL's trained Longformer model from huggingface-hub**  \n",
    "\n",
    "While we can give you the library versions we used for model development and inference, due to the dependence on underlying GPU support, OS, and python versions, we aren't able to guarantee that these versions will work for you. The key is to make sure that the pytorch version installed matches your underlying Python version and CUDA version. Then, install the corresponding transformers version that fits with that version of Pytorch. Everything else is straightforward and less particular. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af08a1ac-ffd1-402b-a0bf-75805411d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to try and install everything as we have it, here's some pip installs\n",
    "\n",
    "# !pip install pandas==1.5.0\n",
    "# !pip install numpy==1.23.4\n",
    "# !pip install tqdm==4.64.1\n",
    "# !pip install torch==1.10.1+cu102 torchvision==0.11.2+cu102 torchaudio==0.10.1 -f https://download.pytorch.org/whl/cu102/torch_stable.html\n",
    "# !pip install transformers==4.20.1\n",
    "# !pip install datasets==2.12.0\n",
    "# !pip install evaluate==0.4.0\n",
    "# !pip install huggingface-hub==0.8.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2d1468-836f-495b-98a1-7dd4bdc204eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now import them! \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import datasets\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89207270-cb7c-4f75-a922-88aba9196101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we also check that we have CUDA working assuming we have it! \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb79e1f-3679-4ec6-be29-c82e596a59bf",
   "metadata": {},
   "source": [
    "## Installing HAIL's Incarceration Status Model\n",
    "\n",
    "Instead of installing the model directly, we can use a pipeline to quickly and efficiently label some notes!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77112d67-c353-4da1-8f79-9ef781abc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "# we assume that we have a GPU, else use CPU\n",
    "BATCH_SIZE = 5\n",
    "pipe = pipeline(\"text-classification\", model=\"vsocrates/incar-status-any\", device=0 if torch.cuda.is_available() else -1, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5af047-44de-4e7b-a808-7e8dbb7e5edd",
   "metadata": {},
   "source": [
    "## Running the Incarceration Status Model\n",
    "\n",
    "\n",
    "Now that we have the prereqs installed and model up and running, we're ready to process some notes! Let's read in a sample file using pandas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f3cd4f-c42b-4fbe-b941-c7ff86fe6caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll create a simple Torch Dataset class so we can get progress bar updates\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ListDataset(Dataset):\n",
    "     def __init__(self, original_list):\n",
    "        self.original_list = original_list\n",
    "     def __len__(self):\n",
    "        return len(self.original_list)\n",
    "\n",
    "     def __getitem__(self, i):\n",
    "        return self.original_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd78e70-fc53-4701-b321-b92426d3540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = pd.read_csv(\"/path/to/sample/data.csv\")\n",
    "\n",
    "# create a huggingface Dataset object from this CSV file\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b1991-3988-420b-ae85-96297db8f21e",
   "metadata": {},
   "source": [
    "We won't show you the file we used since it contains PHI, but it should have a column for an ID and a column for the text, something like: \n",
    "\n",
    "| encounter_ID    | TEXT       |\n",
    "|--------------|--------------|\n",
    "| 1 | Patient arrived in the ED from jail... |\n",
    "| 2 | Transferred to floor with ERT... |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21487212-61d0-4caf-9430-a654d5629abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ListDataset(notes['TEXT'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079c40c3-a6c8-4add-8eb1-b8106be4f217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3cc96788b946bf840feca671358c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the max Longformer size is 4096 tokens, so we can't include more than that\n",
    "labels = []\n",
    "scores = []\n",
    "for pred in tqdm(pipe(dataset, max_length=4096, truncation=True)):\n",
    "    labels.append(pred['label'])\n",
    "    scores.append(pred['score'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd57128-4123-42b5-8139-87109b502699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reject', 'reject', 'reject'] [0.9992249011993408, 0.9992402791976929, 0.9719255566596985]\n"
     ]
    }
   ],
   "source": [
    "# we can check out what the labels and scores lists look like: \n",
    "print(labels[:3], scores[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655912d-521e-45f4-ae27-f0f22fe313e4",
   "metadata": {},
   "source": [
    "There are two possible values for `labels`, either \"accept\" or \"reject\". In our case, \"accept\" means there is a history/presence of incarceration in the note and \"reject\" means there **is not**. \n",
    "\n",
    "Let's add these back onto our dataframe now and output to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74703beb-cad0-4c7f-a257-0f982dd3094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes['label'] = labels\n",
    "notes['score'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15540585-1833-4361-b18d-1e37220a08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes.to_csv(\"/path/to/sample/data_with_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
